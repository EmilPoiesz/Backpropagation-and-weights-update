{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee016b7",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088d72c",
   "metadata": {},
   "source": [
    "### 1. Approach and design choices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c66b456",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "a) In section 2 we are asked to manually propagate the loss. This can be done in PyTorch with the .backwards() function. \n",
    "\n",
    "b)\n",
    "\n",
    "c) The .step() function of the optimizer in PyTorch normally handles updating the weights. \n",
    "\n",
    "d) The SGD algorithm without momentum can easily get stuck in local minima and take a long taime to get there. Momentum is used to make use of the history of the decent to help make better choices of how far to make the next step. The more we move in one direction the higher the momentum. Momentum is a term taken from physics and its use there is analogous to its use in ML.\n",
    "\n",
    "e) The purpose of regularization in SGD to mitigate the influence of outliers. L2 regularization punishes extreme outliers harshly so that the algorithm will prefer a \"smoother curve\". \n",
    "\n",
    "f)\n",
    "\n",
    "g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9512df8d",
   "metadata": {},
   "source": [
    "1. An explanation of your approach and design choices to help us understand how your particular implementation works.\n",
    "2. Answers to the following questions:\n",
    "(a) Which PyTorch method(s) correspond to the tasks described in section 2?\n",
    "(b) Cite a method used to check whether the computed gradient of a function seems correct. Briefly explain how you would use this method to check your computed gradients in section 2.\n",
    "5\n",
    "(c) Which PyTorch method(s) correspond to the tasks described in section 3, question 4.?\n",
    "(d) Briefly explain the purpose of adding momentum to the gradient descent algorithm.\n",
    "(e) Briefly explain the purpose of adding regularization to the gradient descent algorithm.\n",
    "(f) Report the different parameters used in section 3, question 8., the selected parameters in question 9. as well as the evaluation of your selected model.\n",
    "(g) Comment your results. In case you do not get expected results, try to give potential reasons that would explain why your code does not work and/or your results differ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
